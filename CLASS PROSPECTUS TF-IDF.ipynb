{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ADDITIONAL FUNCTIONS\n",
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "\n",
    "pStopWordsList = stopwords.words('english') + stopwords.words('russian')\n",
    "    \n",
    "def process_text_layer(TextLayer, pStopWordsList = []):\n",
    "    txt =  \" \".join([w for w in TextLayer.lower().split() \\\n",
    "                     if (not w in pStopWordsList)])\n",
    "\n",
    "    txt = txt. \\\n",
    "        replace('«', ''). \\\n",
    "        replace('»', ''). \\\n",
    "        replace('(', ''). \\\n",
    "        replace(')', ''). \\\n",
    "        replace('\\[)', ''). \\\n",
    "        replace('\\]', ''). \\\n",
    "        replace('^', ''). \\\n",
    "        replace('\\\\', '')\n",
    "\n",
    "    return txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBinaryClassifier_TF_IDF(ds):\n",
    "    '''Kлассификатор. \n",
    "   Input: ds (dataframe): x - текстовый слой; target - результат\n",
    "   Output: CountVectorizer, RandomForestClassifier\n",
    "   '''\n",
    "    ngram_range = (1, 3)\n",
    "    max_features = 50000\n",
    "    n_estimators=100\n",
    "\n",
    "    print(\"Create vectorizer\")\n",
    "    vectorizer = TfidfVectorizer(analyzer = \"word\",\n",
    "                                tokenizer = None,\n",
    "                                preprocessor = None,\n",
    "                                stop_words = None, \n",
    "                                ngram_range = ngram_range,\n",
    "                                max_features = max_features\n",
    "                                )\n",
    "\n",
    "    print(\"Fit and Transform vectorizer\")\n",
    "\n",
    "    X_train = ds['x']\n",
    "    Y_train = ds['target']\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_train = X_train.toarray()\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    print(\"Fit Model\")\n",
    "    model = model.fit(X_train, Y_train)\n",
    "\n",
    "    return vectorizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learnBinaryClassifier_CountVectorizer(ds):\n",
    "    '''Kлассификатор. \n",
    "   Input: ds (dataframe): x - текстовый слой; target - результат\n",
    "   Output: CountVectorizer, RandomForestClassifier\n",
    "   '''\n",
    "    ngram_range = (1, 3)\n",
    "    max_features = 50000\n",
    "    n_estimators=100\n",
    "\n",
    "    print(\"Create vectorizer\")\n",
    "    vectorizer = CountVectorizer(analyzer = \"word\",\n",
    "                                tokenizer = None,\n",
    "                                preprocessor = None,\n",
    "                                stop_words = None, \n",
    "                                ngram_range = ngram_range,\n",
    "                                max_features = max_features\n",
    "                                )\n",
    "\n",
    "    print(\"Fit and Transform vectorizer\")\n",
    "\n",
    "    X_train = ds['x']\n",
    "    Y_train = ds['target']\n",
    "\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_train = X_train.toarray()\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators)\n",
    "\n",
    "    print(\"Fit Model\")\n",
    "    model = model.fit(X_train, Y_train)\n",
    "\n",
    "    return vectorizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    US105756BX78-ALL\n",
      "1     US105756BX78-55\n",
      "2    XS1433177497-133\n",
      "3    XS1433177497-134\n",
      "4    XS1433177497-135\n",
      "Name: tag, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text_data = pd.read_csv('CLASS PROSPECTUS.csv')\n",
    "text_data['string_value'] = text_data['string_value'].astype(str)\n",
    "class_data = pd.read_excel('CLASS PROSPECTUS.xlsx', sheet_name = 'DATA')\n",
    "\n",
    "models_rename = {\n",
    "    \"Ограничение по предоставлению залога\":\"Restriction_on_the_provision_of_collateral\",\n",
    "    \"Изменение контроля\":\"Change_of_control\",\n",
    "    \"Случаи дефолта\":\"Cases_of_default\",\n",
    "    \"Кросс-дефолт\":\"Cross-default\",\n",
    "    \"Оговорки о коллективных действиях\":\"Collective_action_clauses\",\n",
    "    \"Ограничение задолженности\":\"Limitation_on_indebtedness\",\n",
    "    \"Ограничение задолженности дочерних компаний\":\"Limitation_of_debt_of_subsidiaries\",\n",
    "    \"Ограничение по платежам\":\"Limitation_on_payments\",\n",
    "    \"Ограничение по инвестициям\":\"Investment_restriction\",\n",
    "    \"Ограничение по платежам в отношении дочерних компаний\":\"Limitation_on_payments_to_subsidiaries\",\n",
    "    \"Ограничение по транзакциям с аффилированными лицами\":\"Restriction_on_transactions_with_affiliates\",\n",
    "    \"Ограничение деятельности\":\"Restriction_of_activity\",\n",
    "    \"Ограничение по продаже активов\":\"Restriction_on_asset_sales\",\n",
    "    \"Ограничение по продаже активов с обратной арендой\":\"Restriction_on_the_sale_of_assets_with_leaseback\",\n",
    "    \"Ограничение по слиянию\":\"Limitation_on_merger\",\n",
    "    \"Обозначение прав дочерних компаний (restricted / unrestricted)\":\"Designation_of_the_rights_of_subsidiaries\",\n",
    "    \"Ограничение по наслоению долговых обязательств по рангам\":\"Restriction_on_the_layering_of_debt_obligations_by_rank\",\n",
    "    \"Условие приостановки действия ковенантов\":\"A_condition_of_suspension_of_the_covenants\",\n",
    "    \"Финансовые ковенанты\":\"Financial_covenants\"}\n",
    "class_data = class_data.rename(columns=models_rename)\n",
    "print(class_data['tag'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уменьшаем размерность задачи, так как слишком много нулевых данных\n",
    "tags = list(class_data['tag'])\n",
    "new_tags = list(text_data[~text_data['tag'].isin(tags)].sample(3000)['tag'])\n",
    "new_tags = new_tags + tags\n",
    "text_data = text_data[text_data['tag'].isin(new_tags)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = text_data.merge(class_data, on='tag', how='left').copy()\n",
    "data['string_value'] = data.apply(lambda r: process_text_layer(r['string_value'], pStopWordsList), axis = 1)\n",
    "models = list(data.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = {}\n",
    "#models = ['Change_of_control']\n",
    "for model_name in models:\n",
    "    ds = data[['tag','string_value', model_name]].rename(columns={'string_value': 'x', model_name: 'target'})\n",
    "    ds = ds.fillna(0)\n",
    "    ds = ds[ds['target']!=''].drop_duplicates()\n",
    "    datasets[model_name] = ds.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_set_part = 0.2\n",
    "for model_name in models:\n",
    "    df_validation = datasets[model_name].sample(round(len(datasets[model_name])*validation_set_part)).copy()\n",
    "    item = {\n",
    "        'df_validation': df_validation.copy(),\n",
    "        'df_training': datasets[model_name][datasets[model_name]['tag'].isin(df_validation['tag'].values)==False].copy()\n",
    "    }\n",
    "    datasets[model_name] = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n",
      "Create vectorizer\n",
      "Fit and Transform vectorizer\n",
      "Fit Model\n"
     ]
    }
   ],
   "source": [
    "for model_name in models:\n",
    "    vector, model = learnBinaryClassifier_CountVectorizer(datasets[model_name]['df_training'])\n",
    "    with open(('models/CLASS_PROSPECTUS_%s_CountVectorizer.rft' % model_name), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(('models/VECTOR_PROSPECTUS_%s_CountVectorizer.txt' % model_name), 'wb') as f:\n",
    "        pickle.dump(vector, f)\n",
    "    vector, model = learnBinaryClassifier_TF_IDF(datasets[model_name]['df_training'])\n",
    "    with open(('models/CLASS_PROSPECTUS_%s_TF-IDF.rft' % model_name), 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    with open(('models/VECTOR_PROSPECTUS_%s_TF-IDF.txt' % model_name), 'wb') as f:\n",
    "        pickle.dump(vector, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model CountVectorizer Restriction_on_the_provision_of_collateral statistic (validation rows 685): Precision= 98.69 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Restriction_on_the_provision_of_collateral statistic (validation rows 685): Precision= 98.83 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 98.83\n",
      "Model CountVectorizer Change_of_control statistic (validation rows 685): Precision= 99.85 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Change_of_control statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.85\n",
      "Model CountVectorizer Cases_of_default statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Cases_of_default statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.71\n",
      "Model CountVectorizer Cross-default statistic (validation rows 685): Precision= 98.98 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Cross-default statistic (validation rows 685): Precision= 98.83 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 98.98\n",
      "Model CountVectorizer Collective_action_clauses statistic (validation rows 685): Precision= 99.56 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Collective_action_clauses statistic (validation rows 685): Precision= 99.56 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.56\n",
      "Model CountVectorizer Limitation_on_indebtedness statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Limitation_on_indebtedness statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Limitation_of_debt_of_subsidiaries statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Limitation_of_debt_of_subsidiaries statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Limitation_on_payments statistic (validation rows 685): Precision= 99.85 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Limitation_on_payments statistic (validation rows 685): Precision= 99.85 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.85\n",
      "Model CountVectorizer Investment_restriction statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Investment_restriction statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Limitation_on_payments_to_subsidiaries statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Limitation_on_payments_to_subsidiaries statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Restriction_on_transactions_with_affiliates statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Restriction_on_transactions_with_affiliates statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.71\n",
      "Model CountVectorizer Restriction_of_activity statistic (validation rows 685): Precision= 99.56 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Restriction_of_activity statistic (validation rows 685): Precision= 99.42 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.56\n",
      "Model CountVectorizer Restriction_on_asset_sales statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Restriction_on_asset_sales statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Restriction_on_the_sale_of_assets_with_leaseback statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Restriction_on_the_sale_of_assets_with_leaseback statistic (validation rows 685): Precision= 99.71 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.71\n",
      "Model CountVectorizer Limitation_on_merger statistic (validation rows 685): Precision= 99.27 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Limitation_on_merger statistic (validation rows 685): Precision= 99.27 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.27\n",
      "Model CountVectorizer Триггер рейтингов statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Триггер рейтингов statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Обозначение прав дочерних компаний (restricted unrestricted) statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Обозначение прав дочерних компаний (restricted unrestricted) statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer Restriction_on_the_layering_of_debt_obligations_by_rank statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Restriction_on_the_layering_of_debt_obligations_by_rank statistic (validation rows 685): Precision= 100.0 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 100.0\n",
      "Model CountVectorizer A_condition_of_suspension_of_the_covenants statistic (validation rows 685): Precision= 99.27 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF A_condition_of_suspension_of_the_covenants statistic (validation rows 685): Precision= 99.27 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.27\n",
      "Model CountVectorizer Financial_covenants statistic (validation rows 685): Precision= 99.85 ; To_Validate=0.0  at Confidence=0\n",
      "Model TF-IDF Financial_covenants statistic (validation rows 685): Precision= 99.85 ; To_Validate=0.0  at Confidence=0\n",
      "Best Precision= 99.85\n"
     ]
    }
   ],
   "source": [
    "ds_mistakes_countvectorizer = {}\n",
    "ds_mistakes_tfidf = {}\n",
    "confidence_level = 0\n",
    "for model_name in models:\n",
    "    with open(('models/CLASS_PROSPECTUS_%s_CountVectorizer.rft' % model_name), 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    with open(('models/VECTOR_PROSPECTUS_%s_CountVectorizer.txt' % model_name), 'rb') as f:\n",
    "        vector = pickle.load(f)  \n",
    "    \n",
    "    ds = datasets[model_name]['df_validation']\n",
    "    \n",
    "    ds['predict']= model.predict(vector.transform(ds['x']))\n",
    "    ds['confidence']=np.transpose(np.amax(model.predict_proba(vector.transform(ds['x'])), axis=1))\n",
    "    ds['target'] = ds.apply(lambda r: 'empty' if r['target']==None else r['target'], axis=1)\n",
    "    ds_mistakes_countvectorizer[model_name] = ds[(ds['confidence']>=confidence_level)&(ds['target']!=ds['predict'])]\n",
    "    \n",
    "    precision_countvectorizer = round(100- 100*len(ds[(ds['confidence']>=confidence_level)&(ds['target']!=ds['predict'])])/len(ds),2)\n",
    "    to_validate = round(100*len(ds[(ds['confidence']<confidence_level)])/len(ds),2)\n",
    "    \n",
    "    print('Model CountVectorizer %s statistic (validation rows %s): Precision= %s ; To_Validate=%s  at Confidence=%s' % (model_name, len(ds), precision_countvectorizer, to_validate, confidence_level))\n",
    "    \n",
    "    #TF-IDF\n",
    "    \n",
    "    with open(('models/CLASS_PROSPECTUS_%s_TF-IDF.rft' % model_name), 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    with open(('models/VECTOR_PROSPECTUS_%s_TF-IDF.txt' % model_name), 'rb') as f:\n",
    "        vector = pickle.load(f)  \n",
    "    \n",
    "    ds = datasets[model_name]['df_validation']\n",
    "    \n",
    "    ds['predict']= model.predict(vector.transform(ds['x']))\n",
    "    ds['confidence']=np.transpose(np.amax(model.predict_proba(vector.transform(ds['x'])), axis=1))\n",
    "    ds['target'] = ds.apply(lambda r: 'empty' if r['target']==None else r['target'], axis=1)\n",
    "    ds_mistakes_tfidf[model_name] = ds[(ds['confidence']>=confidence_level)&(ds['target']!=ds['predict'])]\n",
    "    \n",
    "    precision_tfidf = round(100- 100*len(ds[(ds['confidence']>=confidence_level)&(ds['target']!=ds['predict'])])/len(ds),2)\n",
    "    to_validate = round(100*len(ds[(ds['confidence']<confidence_level)])/len(ds),2)\n",
    "    \n",
    "    print('Model TF-IDF %s statistic (validation rows %s): Precision= %s ; To_Validate=%s  at Confidence=%s' % (model_name, len(ds), precision_tfidf, to_validate, confidence_level))\n",
    "    \n",
    "    print(f'Best Precision= {max(precision_countvectorizer, precision_tfidf)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in models:\n",
    "    ds_mistakes_countvectorizer[name].to_excel(f'{name}_CountVectorizer.xlsx')\n",
    "    ds_mistakes_tfidf[name].to_excel(f'{name}_TF-IDF.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
